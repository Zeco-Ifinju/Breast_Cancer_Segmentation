{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb6c8a-98ac-4da8-9ecf-33a26f9de706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325c1c8a-eff1-49bb-8639-897843b82829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e939f01-7a46-4da4-be6d-f4b690a5bef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505c89ea-e49a-4029-965e-47637d97980e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e1e7310-e2ab-4e6b-a552-43bec31511c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the dataset\n",
    "def load_dataset(base_path, class_index, image_size):\n",
    "    images = []\n",
    "    masks = []\n",
    "    filenames = []\n",
    "    for category in class_index:\n",
    "        category_path = os.path.join(base_path, category)\n",
    "        if not os.path.exists(category_path):\n",
    "            raise FileNotFoundError(f\"The category path does not exist: {category_path}\")\n",
    "        \n",
    "        for file in os.listdir(category_path):\n",
    "            if 'mask' not in file:  # Exclude mask files for image loading\n",
    "                image_path = os.path.join(category_path, file)\n",
    "                mask_path = os.path.join(category_path, file.split('.')[0] + '_mask.png')\n",
    "                \n",
    "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                \n",
    "                if image is not None and mask is not None:\n",
    "                    if image.shape == mask.shape:\n",
    "                        image_resized = cv2.resize(image, (image_size, image_size))\n",
    "                        mask_resized = cv2.resize(mask, (image_size, image_size))\n",
    "                        images.append(image_resized)\n",
    "                        masks.append(mask_resized)\n",
    "                        filenames.append(file)\n",
    "                    else:\n",
    "                        print(f\"Warning: Image and mask shape mismatch for {file}\")\n",
    "                else:\n",
    "                    print(f\"Warning: Could not load image or mask for {file}\")\n",
    "\n",
    "    return np.array(images), np.array(masks), filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f7a07c-9340-4d31-9c3a-c4ef1858f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the images\n",
    "def preprocess_images(images, masks):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    masks = masks.astype('float32') / 255.0\n",
    "    masks = np.expand_dims(masks, axis=-1)\n",
    "    return np.expand_dims(images, axis=-1), masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2a32fc4-f6e8-4193-bbed-b8c853efa389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net Model Architecture\n",
    "def unet_model(input_size):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Decoder\n",
    "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
    "    merge6 = concatenate([conv4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = UpSampling2D(size=(2, 2))(conv8)\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs, conv10)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a36bd17e-b0a1-474e-9225-bc69958a61a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base path to the dataset\n",
    "BASE_PATH = \"C:/Users/HP/OneDrive/Desktop/Karatu/Breast_Cancer/Breast_Cancer_Segmentation/Dataset_BUSI_with_GT\" # change the path\n",
    "unique_classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e87fd377-ebfd-4afb-b061-62fcdeba7158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes found: ['benign', 'malignant', 'normal']\n",
      "Class index sorted: ['benign', 'malignant', 'normal']\n"
     ]
    }
   ],
   "source": [
    "# Check if the path exists and list unique classes\n",
    "if os.path.exists(BASE_PATH):\n",
    "    for path in os.listdir(BASE_PATH):\n",
    "        unique_classes.append(path)\n",
    "    print(\"Unique classes found:\", unique_classes)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"The specified path does not exist: {BASE_PATH}\")\n",
    "\n",
    "# Sort classes to ensure consistent order\n",
    "class_index = sorted(unique_classes)\n",
    "print(\"Class index sorted:\", class_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b001a18a-7ddb-4f74-811d-ac8ab18933a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "image_size = 256\n",
    "images, masks, filenames = load_dataset(BASE_PATH, class_index, image_size)\n",
    "images, masks = preprocess_images(images, masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5df28b80-0373-4516-b36a-3c6bc2950eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c04c3d36-ce5e-414f-88c6-8cb76561fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "data_gen_args = dict(rotation_range=10,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     shear_range=0.1,\n",
    "                     zoom_range=0.1,\n",
    "                     horizontal_flip=True,\n",
    "                     fill_mode='nearest')\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc96c5a1-a8b4-4dbd-ad07-9d9f943184fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the same seed and keyword arguments to the flow methods\n",
    "seed = 1\n",
    "image_datagen.fit(X_train, augment=True, seed=seed)\n",
    "mask_datagen.fit(y_train, augment=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f01a66e-20c5-41cf-a728-9188e3ddcab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = image_datagen.flow(X_train, batch_size=16, seed=seed)\n",
    "mask_generator = mask_datagen.flow(y_train, batch_size=16, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01755dd3-2df3-4038-a29a-082a113967ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine generators into one which yields image and masks\n",
    "train_generator = zip(image_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057c803-ab39-460b-a4e3-5e4879755470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      " 1/39 [..............................] - ETA: 1:22:18 - loss: 0.6851 - accuracy: 0.8577"
     ]
    }
   ],
   "source": [
    "# Compile and train the U-Net model\n",
    "input_size = (image_size, image_size, 1)\n",
    "model = unet_model(input_size)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator, steps_per_epoch=len(X_train) // 16, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b26b160-dc10-4add-9a3b-c17ffdec3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e04071-adf9-4903-9b52-ec2fd6c3c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy and loss values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee2c08f-56bb-4638-9453-5338e0e8b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
    "    if ix is None:\n",
    "        ix = np.random.randint(0, len(X))\n",
    "\n",
    "    has_mask = y[ix].max() > 0  # Check if any mask is present in the ground truth\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
    "    ax[0].imshow(X[ix].squeeze(), cmap='gray')\n",
    "    if has_mask:\n",
    "        ax[0].contour(y[ix].squeeze(), colors='r', levels=[0.5])\n",
    "    ax[0].set_title('Original')\n",
    "\n",
    "    ax[1].imshow(y[ix].squeeze(), cmap='gray')\n",
    "    ax[1].set_title('Ground Truth')\n",
    "\n",
    "    ax[2].imshow(preds[ix].squeeze(), cmap='gray')\n",
    "    if has_mask:\n",
    "        ax[2].contour(y[ix].squeeze(), colors='r', levels=[0.5])\n",
    "    ax[2].set_title('Prediction')\n",
    "\n",
    "    ax[3].imshow(binary_preds[ix].squeeze(), cmap='gray')\n",
    "    if has_mask:\n",
    "        ax[3].contour(y[ix].squeeze(), colors='r', levels=[0.5])\n",
    "    ax[3].set_title('Binary Prediction')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa325aa6-fcee-45e3-a8cb-13da9fc40b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the validation set and visualize results\n",
    "preds_val = model.predict(X_test, verbose=1)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "\n",
    "# Plot some examples\n",
    "for i in range(5):\n",
    "    plot_sample(X_test, y_test, preds_val, preds_val_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c795286-0790-4860-a890-71bc1f61ec1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5a8c9c-7798-4c6f-b9fb-a9aa84010197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Create a directory to save the model files if it doesn't exist\n",
    "os.makedirs('saved_model', exist_ok=True)\n",
    "\n",
    "# Save the model architecture to a JSON file\n",
    "model_json = model.to_json()\n",
    "with open(\"saved_model/unet_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save the model weights to an HDF5 file\n",
    "model.save_weights(\"saved_model/unet_model_weights.h5\")\n",
    "\n",
    "print(\"Model architecture and weights saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c95aa5-24b1-4181-8a29-e46dc16be6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, save the model weights in multiple smaller files if the total size exceeds the GitHub limit\n",
    "# This can be achieved by splitting the weight saving process into chunks\n",
    "def save_weights_in_chunks(model, save_dir, max_size=50 * 1024 * 1024):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    weights = model.get_weights()\n",
    "    chunk_index = 0\n",
    "    total_size = 0\n",
    "\n",
    "    for i, weight in enumerate(weights):\n",
    "        weight_file = os.path.join(save_dir, f\"weights_{i}.npy\")\n",
    "        np.save(weight_file, weight)\n",
    "        total_size += os.path.getsize(weight_file)\n",
    "\n",
    "        if total_size > max_size:\n",
    "            chunk_index += 1\n",
    "            total_size = 0\n",
    "\n",
    "        if chunk_index > 0:\n",
    "            chunk_file = os.path.join(save_dir, f\"chunk_{chunk_index}.zip\")\n",
    "            os.system(f\"zip -r {chunk_file} {save_dir}/*.npy\")\n",
    "            os.system(f\"rm {save_dir}/*.npy\")\n",
    "\n",
    "save_weights_in_chunks(model, \"saved_model/weights_chunks\")\n",
    "\n",
    "print(\"Model and weights saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
